{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet-train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0uJsOUDm32yr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd27b612-dcf2-404d-ed29-128495f40d88"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Input, MaxPooling2D\n",
        "from keras.layers import concatenate, Conv2D, Conv2DTranspose, Dropout, ReLU\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from numpy import random\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "import keras\n",
        "from keras_preprocessing import image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "G_hoXdeW4fBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "input_shape = (64, 64)\n",
        "\n",
        "def get_unet(do=0, activation=ReLU):\n",
        "    inputs = Input((None, None, 3))\n",
        "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(inputs)))\n",
        "    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv1)))\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(pool1)))\n",
        "    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv2)))\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(pool2)))\n",
        "    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv3)))\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(pool3)))\n",
        "    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv4)))\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(pool4)))\n",
        "    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(conv5)))\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(up6)))\n",
        "    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv6)))\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(up7)))\n",
        "    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv7)))\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(up8)))\n",
        "    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv8)))\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(up9)))\n",
        "    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv9)))\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def read_input(path):\n",
        "    x = np.array(Image.open(path))/255.\n",
        "    return x\n",
        "\n",
        "\n",
        "def read_gt(path):\n",
        "    x = np.array(Image.open(path))/255.\n",
        "    return x[..., np.newaxis]\n",
        "\n",
        "\n",
        "def random_crop(img, mask, crop_size=input_shape[0]):\n",
        "    imgheight= img.shape[0]\n",
        "    imgwidth = img.shape[1]\n",
        "    i = randint(0, imgheight-crop_size)\n",
        "    j = randint(0, imgwidth-crop_size)\n",
        "\n",
        "    return img[i:(i+crop_size), j:(j+crop_size), :], mask[i:(i+crop_size), j:(j+crop_size)]\n",
        "\n",
        "\n",
        "def gen(data):\n",
        "    while True:\n",
        "        repeat = 4\n",
        "        index= random.choice(list(range(len(data))), batch_size//repeat)\n",
        "        index = list(map(int, index))\n",
        "        list_images_base = [read_input(data[i][0]) for i in index]\n",
        "        list_gt_base = [read_gt(data[i][1]) for i in index]\n",
        "\n",
        "        list_images = []\n",
        "        list_gt = []\n",
        "\n",
        "        for image, gt in zip(list_images_base, list_gt_base):\n",
        "\n",
        "            for _ in range(repeat):\n",
        "                image_, gt_ = random_crop(image.copy(), gt.copy())\n",
        "                list_images.append(image_)\n",
        "                list_gt.append(gt_)\n",
        "\n",
        "        yield np.array(list_images), np.array(list_gt)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIsBsqeq4fWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1251
        },
        "outputId": "f2c4608e-cb4e-4a34-973f-cdea9f3ca57d"
      },
      "cell_type": "code",
      "source": [
        "activation = globals()[\"ReLU\"]\n",
        "dropout = 0.1\n",
        "\n",
        "train_data = np.array(list(zip(sorted(glob('DRIVE/training/images/*.tif')),\n",
        "                      sorted(glob('DRIVE/training/1st_manual/*.gif')))))\n",
        "\n",
        "\n",
        "test_data = np.array(list(zip(sorted(glob('DRIVE/test/images/*.tif')),\n",
        "                      sorted(glob('DRIVE/test/1st_manual/*.gif')))))\n",
        "\n",
        "model = get_unet(do=dropout, activation=activation)\n",
        "history = model.fit_generator(gen(train_data), epochs=30, validation_data=gen(test_data), validation_steps=100*3//batch_size,\n",
        "                            steps_per_epoch= 100*len(train_data)//batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/30\n",
            "125/125 [==============================] - 31s 249ms/step - loss: 0.3613 - acc: 0.8896 - val_loss: 0.3205 - val_acc: 0.8906\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 23s 183ms/step - loss: 0.3094 - acc: 0.8947 - val_loss: 0.3205 - val_acc: 0.8893\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 24s 189ms/step - loss: 0.3008 - acc: 0.8970 - val_loss: 0.3000 - val_acc: 0.8885\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 23s 182ms/step - loss: 0.2373 - acc: 0.9159 - val_loss: 0.1727 - val_acc: 0.9390\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 23s 187ms/step - loss: 0.1700 - acc: 0.9404 - val_loss: 0.1481 - val_acc: 0.9458\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 23s 185ms/step - loss: 0.1523 - acc: 0.9459 - val_loss: 0.1646 - val_acc: 0.9414\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 23s 181ms/step - loss: 0.1427 - acc: 0.9490 - val_loss: 0.1482 - val_acc: 0.9473\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 23s 185ms/step - loss: 0.1410 - acc: 0.9495 - val_loss: 0.1465 - val_acc: 0.9469\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 23s 182ms/step - loss: 0.1397 - acc: 0.9493 - val_loss: 0.1342 - val_acc: 0.9511\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 23s 181ms/step - loss: 0.1304 - acc: 0.9525 - val_loss: 0.1253 - val_acc: 0.9545\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 23s 180ms/step - loss: 0.1299 - acc: 0.9523 - val_loss: 0.1289 - val_acc: 0.9519\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 23s 186ms/step - loss: 0.1291 - acc: 0.9523 - val_loss: 0.1181 - val_acc: 0.9567\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 22s 180ms/step - loss: 0.1169 - acc: 0.9566 - val_loss: 0.1207 - val_acc: 0.9550\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 22s 180ms/step - loss: 0.1223 - acc: 0.9546 - val_loss: 0.1094 - val_acc: 0.9584\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 23s 184ms/step - loss: 0.1169 - acc: 0.9566 - val_loss: 0.1093 - val_acc: 0.9586\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 23s 183ms/step - loss: 0.1149 - acc: 0.9568 - val_loss: 0.1100 - val_acc: 0.9578\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 23s 183ms/step - loss: 0.1161 - acc: 0.9566 - val_loss: 0.1021 - val_acc: 0.9609\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 22s 179ms/step - loss: 0.1132 - acc: 0.9573 - val_loss: 0.1278 - val_acc: 0.9537\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 23s 187ms/step - loss: 0.1097 - acc: 0.9589 - val_loss: 0.1009 - val_acc: 0.9624\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 22s 178ms/step - loss: 0.1100 - acc: 0.9583 - val_loss: 0.1108 - val_acc: 0.9580\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 23s 180ms/step - loss: 0.1131 - acc: 0.9572 - val_loss: 0.1020 - val_acc: 0.9601\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 23s 182ms/step - loss: 0.1117 - acc: 0.9578 - val_loss: 0.1088 - val_acc: 0.9580\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 23s 182ms/step - loss: 0.1087 - acc: 0.9588 - val_loss: 0.1115 - val_acc: 0.9574\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 22s 180ms/step - loss: 0.1074 - acc: 0.9592 - val_loss: 0.1169 - val_acc: 0.9582\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 22s 179ms/step - loss: 0.1085 - acc: 0.9588 - val_loss: 0.1070 - val_acc: 0.9593\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 23s 185ms/step - loss: 0.1057 - acc: 0.9598 - val_loss: 0.0956 - val_acc: 0.9633\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 22s 180ms/step - loss: 0.1047 - acc: 0.9603 - val_loss: 0.1074 - val_acc: 0.9588\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 22s 179ms/step - loss: 0.1054 - acc: 0.9597 - val_loss: 0.1022 - val_acc: 0.9609\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 23s 180ms/step - loss: 0.1026 - acc: 0.9608 - val_loss: 0.1018 - val_acc: 0.9609\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 24s 191ms/step - loss: 0.1008 - acc: 0.9614 - val_loss: 0.0975 - val_acc: 0.9621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x6gB-uEHAx3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"final.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tX-X3pydCvsl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPnyY0bI4fsW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip DRIVE.zip"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}